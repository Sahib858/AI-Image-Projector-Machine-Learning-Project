# -*- coding: utf-8 -*-
"""ECE196_MLProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ukCOBTlBqRSdvVg2Eb66uVNrXZeU3wi7
"""

import h5py
import numpy as np
import pandas as pd
import os
import glob
import cv2
import torch
from keras import Model
import subprocess
from IPython.display import Image
from IPython.display import display
import tensorflow as tf
from keras.utils import get_file
import matplotlib.pyplot as plt
from google.colab import drive
import sys
from tensorflow.keras.applications import vgg19
from keras.utils import plot_model
import keras
from datetime import datetime
from keras.optimizers import SGD
import matplotlib.image as mpimg
import matplotlib.pyplot as plt


device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError("GPU device not found!")
print('Found GPU at: {}'.format(device_name))

# Define the path to the working directory
drive.mount('/content/drive')



#Show the content images
#Show the style images

#def load_image in order to reshape to make it compatible

#import VGG19 model

sys.path.append('/content/drive/MyDrive/AI Picture Style Transfer Examples')

result_prefix = "Photo_generated"

style_image_path = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Style/GTA Style.jpg", 
                            origin="https://drive.google.com/file/d/1pqy9N7Uaucev3c1oaUBydyGSk6gQe0db/view?usp=sharing")
content_image_path = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Content/Turtle Content.jpg", 
                              origin="https://drive.google.com/file/d/1kJBRVsotv3jgvTd4zRm8AsXYv8hskIWc/view?usp=sharing")

"""# Turtle Content Vs GTA Style Photograph"""

# read the image file in a numpy array
a = plt.imread(content_image_path)
b = plt.imread(style_image_path)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

#Neural Style Transfer

#The Gram Matrix allows us to calculate the style loss on a layer. 
#It shows the similarity between the filters and is obtained by 
#calculating the dot product between the vectors. Each of the 
#calculations will not change based on the size of the layer.
def gram_matrix(x):
    x = tf.transpose(x, (2, 0, 1))
    features = tf.reshape(x, (tf.shape(x)[0], -1))
    gram = tf.matmul(features, tf.transpose(features))
    return gram

#Loss Function of the style
def loss_function_Style(style, combination):
    S = gram_matrix(style)
    C = gram_matrix(combination)
    channels = 3
    size = img_nrows * img_ncols
    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))

#Content Loss function
def content_loss_Function(base, combination):
    return tf.reduce_sum(tf.square(combination - base))

#Load The VGG19 Model
#This is a classification convolutional neural network. The reason already 
#created neural networks are used. is because the VGG19 network is trained 
#with the ImageNet dataset, which is a neural network offered by Keras.

model = vgg19.VGG19(weights="imagenet", include_top=False)
model.summary()

# Function that extracts the values of that model for some given layers 
# so it can used it both for the content error and the style error.
outputs_dict= dict([(layer.name, layer.output) for layer in model.layers])
feature_extractor = Model(inputs=model.inputs, outputs=outputs_dict)

# The Keras package allows us to define: which layers are going to be used to 
# calculate the loss function of the style and which layer we are going to use 
# to calculate the loss function of the content.


#1. Combine all the images in the same tensioner.
#2. Get the values in all the layers for the three images. 
#3. Initialize the loss vector where we will add the results.
#4. Extract the content layers for the base image and merge and calculate the content loss function.
#5. Extract the style layers for the style image and the combination image and calculate the style loss function.

convolution_blocks = [
    "block1_conv1",
    "block2_conv1",
    "block3_conv1",
    "block4_conv1",
    "block5_conv1",
]

convolution_Block_Content = "block5_conv2"

content_weight = 2.5e-8
style_weight = 1e-6

def loss_function(combination_image, base_image, style_reference_image):

    # 1. Combine all the images in the same tensioner.
    input_tensor = tf.concat(
        [base_image, style_reference_image, combination_image], axis=0
    )

    # 2. Get the values in all the layers for the three images.
    features = feature_extractor(input_tensor)

    #3. Inicializar the loss

    loss = tf.zeros(shape=())

    # 4. Extract the content layers + content loss
    layer_features = features[convolution_Block_Content]
    base_image_features = layer_features[0, :, :, :]
    combination_features = layer_features[2, :, :, :]

    loss = loss + content_weight * content_loss_Function(
        base_image_features, combination_features
    )
    # 5. Extract the style layers + style loss
    for layer_name in convolution_blocks:
        layer_features = features[layer_name]
        style_reference_features = layer_features[1, :, :, :]
        combination_features = layer_features[2, :, :, :]
        sl = loss_function_Style(style_reference_features, combination_features)
        loss += (style_weight / len(convolution_blocks)) * sl

    return loss

#Optimization and Gradients

# With the cost function calculate the deltas, which are what gradient descent 
# (or any other optimizer) uses to find our optimal values.
# Tensorflow with the GradientTape
# Gradients will only be calculated with the base image
@tf.function
def compute_loss_and_grads(combination_image, base_image, style_reference_image):
    with tf.GradientTape() as tape:
        loss = loss_function(combination_image, base_image, style_reference_image)
    grads = tape.gradient(loss, combination_image)
    return loss, grads

# Preprocessing of the images consists of giving the images the format that our network requires
def preprocess_image(image_path):
    # Util function to open, resize and format pictures into appropriate tensors
    img = keras.preprocessing.image.load_img(
        image_path, target_size=(img_nrows, img_ncols)
    )
    img = keras.preprocessing.image.img_to_array(img)
    img = np.expand_dims(img, axis=0)
    img = vgg19.preprocess_input(img)
    return tf.convert_to_tensor(img)

def deprocess_image(x):

    # Convert Tensor in Array
    x = x.reshape((img_nrows, img_ncols, 3))

    # Hacemos que no tengan promedio 0
    x[:, :, 0] += 103.939
    x[:, :, 1] += 116.779
    x[:, :, 2] += 123.68

    # Convert BGR to RGB.
    x = x[:, :, ::-1]

    # There should be no values outside
    x = np.clip(x, 0, 255).astype("uint8")

    return x

# Training of our Neural Style Transfer network
# Save the generated images
def result_saver(iteration):
  # Create name
  now = datetime.now()
  now = now.strftime("%Y%m%d_%H%M%S")
  model_name = str(i) + '_' + str(now)+"_model_" + '.h5'
  image_name = str(i) + '_' + str(now)+"_image" + '.png'

  # Save image
  img = deprocess_image(combination_image.numpy())
  keras.preprocessing.image.save_img(image_name, img)

"""# Turtle GTA Style Image"""

#Run Program
width, height = keras.preprocessing.image.load_img(content_image_path).size
img_nrows = 400
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

content_image = preprocess_image(content_image_path)
style_reference_image = preprocess_image(style_image_path)
combination_image = tf.Variable(preprocess_image(content_image_path))

iterations = 4000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, content_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 10 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        img = deprocess_image(combination_image.numpy())
        fname = result_prefix + "_at_iteration_%d.png" % i
        keras.preprocessing.image.save_img(fname, img)
        result_saver(i)

display(Image(result_prefix + "_at_iteration_4000.png"))

"""#Hobbit House Lowfi Style Image"""

style_image_path2 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Style/LowFiStyle.jpg", 
                            origin="https://drive.google.com/file/d/1h0MQBr6VO7QyBa-pQbF34Hm3E0Gfw6j2/view?usp=sharing")
content_image_path2 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Content/HobbitHouse.jpg", 
                              origin="https://drive.google.com/file/d/1xkB0pKCRUqssUKB3uEG8MI76-EnW744p/view?usp=sharing")

# read the image file in a numpy array
a = plt.imread(content_image_path2)
b = plt.imread(style_image_path2)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

#Run Program
width, height = keras.preprocessing.image.load_img(content_image_path2).size
img_nrows = 400
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

content_image = preprocess_image(content_image_path2)
style_reference_image = preprocess_image(style_image_path2)
combination_image = tf.Variable(preprocess_image(content_image_path2))

iterations = 4000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, content_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 10 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        img = deprocess_image(combination_image.numpy())
        fname = result_prefix + "_at_iteration_%d.png" % i
        keras.preprocessing.image.save_img(fname, img)
        result_saver(i)

display(Image(result_prefix + "_at_iteration_4000.png"))

"""#Beach Orange Tree Style Image"""

style_image_path3 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Style/OrangeTreeStyle.jpg", 
                            origin="https://drive.google.com/file/d/1h0MQBr6VO7QyBa-pQbF34Hm3E0Gfw6j2/view?usp=sharing")
content_image_path3 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Content/Beach.jpg", 
                              origin="https://drive.google.com/file/d/1xkB0pKCRUqssUKB3uEG8MI76-EnW744p/view?usp=sharing")

# read the image file in a numpy array
a = plt.imread(content_image_path3)
b = plt.imread(style_image_path3)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

#Run Program
width, height = keras.preprocessing.image.load_img(content_image_path3).size
img_nrows = 400
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

content_image = preprocess_image(content_image_path3)
style_reference_image = preprocess_image(style_image_path3)
combination_image = tf.Variable(preprocess_image(content_image_path3))

iterations = 4000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, content_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 10 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        img = deprocess_image(combination_image.numpy())
        fname = result_prefix + "_at_iteration_%d.png" % i
        keras.preprocessing.image.save_img(fname, img)
        result_saver(i)

display(Image(result_prefix + "_at_iteration_4000.png"))

"""#Rock Space Light Style Image"""

style_image_path4 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Style/SpaceStyleLight.jpg", 
                            origin="https://drive.google.com/file/d/1h0MQBr6VO7QyBa-pQbF34Hm3E0Gfw6j2/view?usp=sharing")
content_image_path4 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Content/Rock.jpg", 
                              origin="https://drive.google.com/file/d/1xkB0pKCRUqssUKB3uEG8MI76-EnW744p/view?usp=sharing")

# read the image file in a numpy array
a = plt.imread(content_image_path4)
b = plt.imread(style_image_path4)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

#Run Program
width, height = keras.preprocessing.image.load_img(content_image_path4).size
img_nrows = 400
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

content_image = preprocess_image(content_image_path4)
style_reference_image = preprocess_image(style_image_path4)
combination_image = tf.Variable(preprocess_image(content_image_path4))

iterations = 4000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, content_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 10 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        img = deprocess_image(combination_image.numpy())
        fname = result_prefix + "_at_iteration_%d.png" % i
        keras.preprocessing.image.save_img(fname, img)
        result_saver(i)

display(Image(result_prefix + "_at_iteration_4000.png"))

"""#Rose Space Dark Style Image"""

style_image_path5 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Style/SpaceStyleDark.jpg", 
                            origin="https://drive.google.com/file/d/1h0MQBr6VO7QyBa-pQbF34Hm3E0Gfw6j2/view?usp=sharing")
content_image_path5 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Content/Rose.jpg", 
                              origin="https://drive.google.com/file/d/1xkB0pKCRUqssUKB3uEG8MI76-EnW744p/view?usp=sharing")

# read the image file in a numpy array
a = plt.imread(content_image_path5)
b = plt.imread(style_image_path5)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

#Run Program
width, height = keras.preprocessing.image.load_img(content_image_path5).size
img_nrows = 400
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

content_image = preprocess_image(content_image_path5)
style_reference_image = preprocess_image(style_image_path5)
combination_image = tf.Variable(preprocess_image(content_image_path5))

iterations = 4000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, content_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 10 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        img = deprocess_image(combination_image.numpy())
        fname = result_prefix + "_at_iteration_%d.png" % i
        keras.preprocessing.image.save_img(fname, img)
        result_saver(i)

display(Image(result_prefix + "_at_iteration_4000.png"))

"""#Girl Drawing Style Image"""

style_image_path7 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Style/GirlDrawingStyle.jpg", 
                            origin="https://drive.google.com/file/d/1h0MQBr6VO7QyBa-pQbF34Hm3E0Gfw6j2/view?usp=sharing")
content_image_path7 = get_file(fname="/content/drive/MyDrive/AI Picture Style Transfer Examples/Content/GirlDrawing.jpg", 
                              origin="https://drive.google.com/file/d/1xkB0pKCRUqssUKB3uEG8MI76-EnW744p/view?usp=sharing")

# read the image file in a numpy array
a = plt.imread(content_image_path7)
b = plt.imread(style_image_path7)
f, axarr = plt.subplots(1,2, figsize=(15,15))
axarr[0].imshow(a)
axarr[1].imshow(b)
plt.show()

#Run Program
width, height = keras.preprocessing.image.load_img(content_image_path7).size
img_nrows = 400
img_ncols = int(width * img_nrows / height)

optimizer = SGD(
    keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96
    )
)

content_image = preprocess_image(content_image_path7)
style_reference_image = preprocess_image(style_image_path7)
combination_image = tf.Variable(preprocess_image(content_image_path7))

iterations = 4000

for i in range(1, iterations + 1):
    loss, grads = compute_loss_and_grads(
        combination_image, content_image, style_reference_image
    )
    optimizer.apply_gradients([(grads, combination_image)])
    if i % 10 == 0:
        print("Iteration %d: loss=%.2f" % (i, loss))
        img = deprocess_image(combination_image.numpy())
        fname = result_prefix + "_at_iteration_%d.png" % i
        keras.preprocessing.image.save_img(fname, img)
        result_saver(i)

display(Image(result_prefix + "_at_iteration_4000.png"))